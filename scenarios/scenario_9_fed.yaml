services:
  
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    hostname: rabbitmq
    ports:
      - 5672:5672
      - 15672:15672
    env_file:
      - ../defaults/rabbitmq_server.env

  # influxdb:
  #   image: influxdb:2.0
  #   container_name: influxdb
  #   hostname: influxdb
  #   ports:
  #     - 8086:8086
  #   env_file:
  #     - ../defaults/influxdb_server.env

  # file_multisensor:
  #   image: "chronis10/teaching-sensors:${ARCH:-amd64}"
  #   container_name: file_multisensor
  #   depends_on:
  #     - rabbitmq
  #   restart: on-failure
  #   environment:
  #     - SERVICE_TYPE=file.csv_feed.CSVFeed
  #     - SERVICE_NAME=file_multisensor
  #     - FILE_PATH=./raw_data/carla/multisensor_carla.csv 
  #     - TRANSMIT_RATE=0.1
  #     - OUTPUT_TOPIC=sensor.carla.value
  #   env_file:
  #     - ../defaults/rabbitmq_client.env
  #   volumes:
  #     - ../raw_data:/app/raw_data

  fed_server:
    image: "chronis10/teaching-ai-toolkit:${ARCH:-amd64}"
    container_name: fed_server
    environment:
      - SERVICE_TYPE=federated.server.FederatedServer
      - SERVICE_NAME=fed_server
      - MODE=FEDERATED
      - KAFKA_HOST=node249-hpc.isti.cnr.it
      - KAFKA_PORT=9092
      - GROUPID=3
      - MODEL_TOPIC=federated.rlmodule.global_model
      - FED_TOPICS=federated.rlmodule.local_model
      - NUM_MSG=2
      - client_model_prefix=rlmodule
      - client_model_ext=h5
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
    volumes:
      - ../data_storage:/app/storage
      - ../../teaching-ai-toolkit/federated:/app/federated

  rl_predictor_1:
    image: "chronis10/teaching-ai-toolkit:${ARCH:-amd64}"
    container_name: rl_module_1
    depends_on: 
      - rabbitmq
      - fed_server
    restart: on-failure
    environment:
      - SERVICE_TYPE=modules.rl_module.RLModule
      - SERVICE_NAME=rl_module_1
      - MODE=FEDERATED
      - KAFKA_HOST=node249-hpc.isti.cnr.it
      - KAFKA_PORT=9092
      - GROUPID=1
      - TOPICS=*.*.value
      - MODEL_PATH=/app/storage/RL/RL_model_episode_470_77.6718928615904.h5
      - SEND_MODEL_INTERVAL=2
      - FED_TOPICS=federated.rlmodule.global_model
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
    env_file:
      - ../defaults/rabbitmq_client.env
    volumes:
      - ../data_storage:/app/storage
      - ../../teaching-ai-toolkit/modules:/app/modules
      - ../../teaching-ai-toolkit/federated:/app/federated
  
  rl_predictor_2:
    image: "chronis10/teaching-ai-toolkit:${ARCH:-amd64}"
    container_name: rl_module_2
    depends_on: 
      - rabbitmq
      - fed_server
    restart: on-failure
    environment:
      - SERVICE_TYPE=modules.rl_module.RLModule
      - SERVICE_NAME=rl_module_2
      - MODE=FEDERATED
      - KAFKA_HOST=node249-hpc.isti.cnr.it
      - KAFKA_PORT=9092
      - GROUPID=2
      - TOPICS=*.*.value
      - MODEL_PATH=/app/storage/RL/RL_model_episode_470_77.6718928615904.h5
      - SEND_MODEL_INTERVAL=2
      - FED_TOPICS=federated.rlmodule.global_model
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
    env_file:
      - ../defaults/rabbitmq_client.env
    volumes:
      - ../data_storage:/app/storage
      - ../../teaching-ai-toolkit/modules:/app/modules
      - ../../teaching-ai-toolkit/federated:/app/federated


  # influxdb_logger:
  #   image: "chronis10/teaching-data:${ARCH:-amd64}"
  #   container_name: influxdb_logger
  #   depends_on:
  #     - rabbitmq
  #     - influxdb
  #   restart: on-failure
  #   environment:
  #     - SERVICE_TYPE=influxdb.client.InfluxDBClientHandler
  #     - SERVICE_NAME=influxdb_logger
  #     - TOPICS=*.*.value
  #   env_file:
  #     - ../defaults/rabbitmq_client.env
  #     - ../defaults/influxdb_client.env